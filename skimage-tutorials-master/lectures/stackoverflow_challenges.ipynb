{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import (filter as filters, io, color,\n",
    "                     exposure, segmentation, morphology, img_as_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snakes\n",
    "\n",
    "Based on http://stackoverflow.com/questions/8686926/python-image-processing-help-needed-for-corner-detection-in-preferably-pil-or/9173430#9173430\n",
    "\n",
    "<img src=\"../images/snakes.png\" width=\"200px\" style=\"float: left; padding-right: 1em;\"/>\n",
    "\n",
    "Consider the zig-zaggy snakes on the left (``../images/snakes.png``).  Write some code to find the begin- and end-points of each.\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "*Hints:*\n",
    "\n",
    "1. Binarize and skeletonize (``morphology.skeletonize``)\n",
    "2. Locate corners via convolution (``scipy.signal.convolve2d``)\n",
    "3. Find intersections between corners and snakes (``np.logical_and``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "img = color.rgb2gray(io.imread('../images/snakes.png'))\n",
    "\n",
    "# Reduce all lines to one pixel thickness\n",
    "snakes = morphology.skeletonize(img < 1)\n",
    "\n",
    "# Find pixels with only one neighbor\n",
    "corners = convolve2d(snakes, [[1, 1, 1],\n",
    "                              [1, 0, 1],\n",
    "                              [1, 1, 1]], mode='same') == 1\n",
    "corners = corners & snakes\n",
    "\n",
    "# Those are the start and end positions of the segments\n",
    "y, x = np.where(corners)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(img, cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.scatter(x, y)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters of a pill\n",
    "\n",
    "(Based on StackOverflow http://stackoverflow.com/questions/28281742/fitting-a-circle-to-a-binary-image)\n",
    "\n",
    "<img src=\"../images/round_pill.jpg\" width=\"200px\" style=\"float: left; padding-right: 1em;\"/>\n",
    "Consider a pill from the [NLM Pill Image Recognition Pilot](http://pir.nlm.nih.gov/pilot/instructions.html) (``../images/round_pill.jpg``).  Fit a circle to the pill outline and compute its area.\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "*Hints:*\n",
    "\n",
    "1. Equalize (``exposure.equalize_*``)\n",
    "2. Detect edges (``filter.canny`` or ``feature.canny``--depending on your version)\n",
    "3. Fit the ``CircleModel`` using ``measure.ransac``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = io.imread(\"../images/round_pill.jpg\")\n",
    "image_equalized = exposure.equalize_adapthist(image)\n",
    "edges = filters.canny(color.rgb2gray(image_equalized))\n",
    "\n",
    "f, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(15, 8))\n",
    "ax0.imshow(image)\n",
    "ax1.imshow(image_equalized)\n",
    "ax2.imshow(edges, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "coords = np.column_stack(np.nonzero(edges))\n",
    "\n",
    "model, inliers = measure.ransac(coords, measure.CircleModel,\n",
    "                                min_samples=3, residual_threshold=1,\n",
    "                                max_trials=500)\n",
    "\n",
    "print('Circle parameters:', model.params)\n",
    "\n",
    "row, col, radius = model.params\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.imshow(image, cmap='gray');\n",
    "circle = plt.Circle((col, row), radius=radius, edgecolor='green', linewidth=2, fill=False)\n",
    "ax.add_artist(circle);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viscous fingers\n",
    "\n",
    "Based on StackOverflow: http://stackoverflow.com/questions/23121416/long-boundary-detection-in-a-noisy-image\n",
    "\n",
    "<img src=\"../images/fingers.png\" width=\"200px\" style=\"float: left; padding-right: 1em;\"/>\n",
    "\n",
    "Consider the fluid experiment on the right.  Determine any kind of meaningful boundary.\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "*Hints:*\n",
    "\n",
    "1. Convert to grayscale\n",
    "2. Try edge detection (``filters.canny``)\n",
    "3. If edge detection fails, denoising is needed (try ``restoration.denoise_tv_bregman``)\n",
    "4. Try edge detection (``filters.canny``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import restoration, color, io, filter as filters, morphology\n",
    "\n",
    "image = color.rgb2gray(io.imread('../images/fingers.png'))\n",
    "denoised = restoration.denoise_tv_bregman(image, 1)\n",
    "edges = filters.canny(denoised, low_threshold=0.01, high_threshold=0.21)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "axes[0].imshow(denoised, cmap='gray')\n",
    "axes[1].imshow(edges, cmap='gray')\n",
    "for ax in axes:\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting coins\n",
    "\n",
    "Based on StackOverflow http://stackoverflow.com/questions/28242274/count-number-of-objects-using-watershed-algorithm-scikit-image\n",
    "\n",
    "Consider the coins image from the scikit-image example dataset, shown below.\n",
    "Write a function to count the number of coins.\n",
    "\n",
    "The procedure outlined here is a bit simpler than in the notebook lecture (and works just fine!)\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "*Hint:*\n",
    "\n",
    "1. Equalize\n",
    "2. Threshold (``filter.otsu`` or ``filters.otsu``, depending on version)\n",
    "3. Remove objects touching boundary (``segmentation.clear_border``)\n",
    "4. Apply morphological closing (``morphology.closing``)\n",
    "5. Remove small objects (``measure.regionprops``)\n",
    "6. Visualize (potentially using ``color.label2rgb``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "plt.imshow(data.coins(), cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from skimage import segmentation\n",
    "\n",
    "image = data.coins()\n",
    "equalized = exposure.equalize_adapthist(image)\n",
    "edges = equalized > filters.threshold_otsu(equalized)\n",
    "edges = segmentation.clear_border(edges)\n",
    "edges = morphology.closing(edges, morphology.square(3))\n",
    "\n",
    "f, (ax0, ax1) = plt.subplots(1, 2)\n",
    "ax0.imshow(image, cmap='gray')\n",
    "ax1.imshow(edges, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = measure.label(edges)\n",
    "for region in measure.regionprops(labels):\n",
    "    if region.area < 200:\n",
    "        rows, cols = region.coords.T\n",
    "        labels[rows, cols] = 0\n",
    "\n",
    "print(\"Number of coins:\", len(np.unique(labels)) - 1)\n",
    "        \n",
    "out = color.label2rgb(labels, image, bg_label=0)\n",
    "plt.imshow(out);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color wheel\n",
    "\n",
    "Based on http://stackoverflow.com/questions/21618252/get-blue-colored-contours-using-scikit-image-opencv/21661395#21661395\n",
    "\n",
    "<img src=\"../images/color-wheel.jpg\" width=\"200px\" style=\"float: left; padding-right: 1em;\"/>\n",
    "<img src=\"../images/balloon.jpg\" width=\"200px\" style=\"float: right; padding-left: 1em;\"/>\n",
    "    \n",
    "Consider the color wheel (``../images/color-wheel.jpg``) or the balloon (``../images/balloon.jpg``). Isolate all the blue-ish colors in the top quadrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import img_as_float\n",
    "\n",
    "image = img_as_float(io.imread('../images/color-wheel.jpg'))\n",
    "\n",
    "blue_lab = color.rgb2lab([[[0, 0, 1.]]])\n",
    "light_blue_lab = color.rgb2lab([[[0, 1, 1.]]])\n",
    "red_lab = color.rgb2lab([[[1, 0, 0.]]])\n",
    "image_lab = color.rgb2lab(image)\n",
    "\n",
    "distance_blue = color.deltaE_cmc(blue_lab, image_lab, kL=0.5, kC=0.5)\n",
    "distance_light_blue = color.deltaE_cmc(light_blue_lab, image_lab, kL=0.5, kC=0.5)\n",
    "distance_red = color.deltaE_cmc(red_lab, image_lab, kL=0.5, kC=0.5)\n",
    "distance = distance_blue + distance_light_blue - distance_red\n",
    "distance = exposure.rescale_intensity(distance)\n",
    "\n",
    "image_blue = image.copy()\n",
    "image_blue[distance > 0.3] = 0\n",
    "\n",
    "f, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax0.imshow(image)\n",
    "ax1.imshow(distance, cmap='gray')\n",
    "ax2.imshow(image_blue)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand-coin\n",
    "\n",
    "Based on StackOverflow http://stackoverflow.com/questions/27910187/how-do-i-calculate-the-measurements-of-a-hand-using-scikit-image\n",
    "\n",
    "<img src=\"../images/hand-coin.jpg\" width=\"200px\" style=\"float: left; padding-right: 1em;\"/>\n",
    "\n",
    "Consider the image of the hand and the coin (``../images/hand-coin.jpg``). Roughly isolate the region of the hand and plot its orientation.\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "*Hint:*\n",
    "\n",
    "1. Segment the image, using ``segmentation.slic``\n",
    "2. Compute the region properties of the resulting labeled image\n",
    "3. Select the largest and second largest (non-background) region--the hand and the coin\n",
    "4. For the hand, use ``region.major_axis_length`` and ``region.orientation`` (where region\n",
    "   is your region property) to plot its orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = io.imread(\"../images/hand-coin.jpg\")\n",
    "\n",
    "label_image = segmentation.slic(image, n_segments=2)\n",
    "label_image = measure.label(label_image)\n",
    "\n",
    "regions = measure.regionprops(label_image)\n",
    "areas = [r.area for r in regions]\n",
    "ix = np.argsort(areas)\n",
    "\n",
    "hand = regions[ix[-1]]\n",
    "coin = regions[ix[-2]]\n",
    "\n",
    "selected_labels = np.zeros_like(image[..., 0], dtype=np.uint8)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(8, 8))\n",
    "\n",
    "for n, region in enumerate([hand, coin]):\n",
    "    selected_labels[region.coords[:, 0], region.coords[:, 1]] = n + 2\n",
    "\n",
    "    y0, x0 = region.centroid\n",
    "    orientation = region.orientation\n",
    "\n",
    "    x1 = x0 + np.cos(orientation) * 0.5 * region.major_axis_length\n",
    "    y1 = y0 - np.sin(orientation) * 0.5 * region.major_axis_length\n",
    "    x2 = x0 - np.sin(orientation) * 0.5 * region.minor_axis_length\n",
    "    y2 = y0 - np.cos(orientation) * 0.5 * region.minor_axis_length\n",
    "\n",
    "    ax.plot((x0, x1), (y0, y1), '-r', linewidth=2.5)\n",
    "    ax.plot((x0, x2), (y0, y2), '-r', linewidth=2.5)\n",
    "    ax.plot(x0, y0, '.g', markersize=15)\n",
    "\n",
    "image_label_overlay = color.label2rgb(selected_labels, image=image, bg_label=0)\n",
    "ax.imshow(image_label_overlay, cmap='gray')\n",
    "ax.axis('image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"height: 400px;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".rendered_html {\n",
       "    font-family: Georgia, serif;\n",
       "    font-size: 130%;\n",
       "    line-height: 1.5;\n",
       "}\n",
       "\n",
       ".input {\n",
       "    width: 930px;\n",
       "}\n",
       "\n",
       ".inner_cell {\n",
       "    width: 800px;\n",
       "}\n",
       "\n",
       ".code_cell {\n",
       "    width: 800px;\n",
       "}\n",
       "\n",
       ".CodeMirror-sizer {\n",
       "}\n",
       "\n",
       "hr {\n",
       "    border: 1px solid #DDD;\n",
       "}\n",
       "\n",
       ".rendered_html h1 {\n",
       "    margin: 0.25em 0em 0.5em;\n",
       "    font-family: sans-serif;\n",
       "    color: #015C9C;\n",
       "    text-align: center;\n",
       "    line-height: 1.2;\n",
       "    page-break-before: always;\n",
       "}\n",
       "\n",
       ".rendered_html h2 {\n",
       "    margin: 1.1em 0em 0.5em;\n",
       "    font-family: sans-serif;\n",
       "    color: #26465D;\n",
       "    line-height: 1.2;\n",
       "}\n",
       "\n",
       ".rendered_html h3 {\n",
       "    font-family: sans-serif;\n",
       "    margin: 1.1em 0em 0.5em;\n",
       "    color: #002845;\n",
       "    line-height: 1.2;\n",
       "}\n",
       "\n",
       ".rendered_html li {\n",
       "    line-height: 1.5;\n",
       "}\n",
       "\n",
       ".CodeMirror-lines {\n",
       "    font-size: 110%;\n",
       "    line-height: 1.4em;\n",
       "    font-family: DejaVu Sans Mono, Consolas, Ubuntu, monospace;\n",
       "}\n",
       "\n",
       "h1.bigtitle {\n",
       "    margin: 4cm 1cm 4cm 1cm;\n",
       "    font-size: 300%;\n",
       "}\n",
       "\n",
       "h3.point {\n",
       "    font-size: 200%;\n",
       "    text-align: center;\n",
       "    margin: 2em 0em 2em 0em;\n",
       "    #26465D\n",
       "}\n",
       "\n",
       ".logo {\n",
       "    margin: 20px 0 20px 0;\n",
       "}\n",
       "\n",
       "a.anchor-link {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       "h1.title {\n",
       "    font-size: 250%;\n",
       "}\n",
       "\n",
       ".exercize {\n",
       "    color: #738;\n",
       "}\n",
       "\n",
       "h2 .exercize {\n",
       "    font-style: italic;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0x7f2f79c519e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext load_style\n",
    "%load_style ../themes/tutorial.css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
